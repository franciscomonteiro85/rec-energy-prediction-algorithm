{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58081526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, KFold, RepeatedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import time\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6963e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"../Dataset.xlsx\", sheet_name=['Total Consumers'])\n",
    "df = data['Total Consumers']\n",
    "number_of_houses = len(df.columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9d325",
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(preds: np.array, actuals: np.array, title: str):\n",
    "    \n",
    "    plt.scatter(actuals, preds, c='b', label='predicted')\n",
    "    plt.xlabel('actual')\n",
    "    plt.ylabel('predicted')\n",
    "    plt.title(title)\n",
    "    plt.xlim(0, plt.xlim()[1])\n",
    "    plt.ylim(0, plt.ylim()[1])\n",
    "    _ = plt.plot([0, 100], [0, 100], '--r', label='y=x')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def performance_metrics(preds: np.array, actuals: np.array):\n",
    "\n",
    "    # calculate performance metrics\n",
    "    \n",
    "    mse = mean_squared_error(actuals, preds)\n",
    "    mae = mean_absolute_error(actuals, preds)\n",
    "    rmse = np.sqrt(mse)\n",
    "    wape = np.sum(np.abs(preds - actuals)) / np.sum(np.abs(actuals)) * 100\n",
    "    #mape = np.mean(np.abs((actuals - preds) / actuals)) * 100\n",
    "    #mape = mae / actuals.mean()  \n",
    "    r2 = r2_score(actuals, preds)\n",
    "\n",
    "    # print performance metrics\n",
    "    #print('MSE: %.4f' % mse)\n",
    "    #print('RMSE: %.4f' % rmse)\n",
    "    #print('MAE: %.4f' % mae)\n",
    "    #print('WMAPE: %.4f' % wmape)\n",
    "    print('WAPE: %.3f' % wape)\n",
    "    #print('R2: %.4f' % r2)\n",
    "    return mse, rmse, mae, wape, r2\n",
    "\n",
    "def build_model(estimator, X_train: np.array, y_train: np.array, X_test: np.array):\n",
    "    \n",
    "    model = estimator\n",
    "    model.fit(X_train, y_train.values.ravel())\n",
    "    preds = model.predict(X_test)\n",
    "    scores = cross_validate(estimator, X_train, y_train.values.ravel(), scoring=['r2', 'neg_root_mean_squared_error', 'neg_mean_squared_error', 'neg_mean_absolute_error'])\n",
    "    return model, preds, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af19e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_averaged_metrics(metrics_list):\n",
    "    \n",
    "    print(\"Total Averaged MSE: {}\".format(np.round(sum(i for i, j, k, l, m in metrics_list)/len(metrics_list),3)))\n",
    "    print(\"Total Averaged RMSE: {}\".format(np.round(sum(j for i, j, k, l, m in metrics_list)/len(metrics_list),3)))\n",
    "    print(\"Total Averaged MAE: {}\".format(np.round(sum(k for i, j, k, l, m in metrics_list)/len(metrics_list),3)))\n",
    "    print(\"Total Averaged WAPE: {}\".format(np.round(sum(l for i, j, k, l, m in metrics_list)/len(metrics_list),3)))\n",
    "    print(\"Total Averaged R2: {}\".format(np.round(sum(m for i, j, k, l, m in metrics_list)/len(metrics_list),3)))\n",
    "\n",
    "\n",
    "def last_energy_points(df, number_timesteps):\n",
    "    X = pd.DataFrame()\n",
    "    for i in range(1, (number_timesteps + 1) ):\n",
    "        X[f'Energy_{i*15}'] = df.shift(i)\n",
    "    X.dropna(inplace=True)\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y = pd.DataFrame(df[number_timesteps:])\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    y.columns = [\"Energy\"]\n",
    "    return X, y\n",
    "\n",
    "def build_predict_show(df, number_timesteps, estimator, train_size=0.8, start_timestep=1 ):\n",
    "    full_start = time.time()\n",
    "    metrics_list = []\n",
    "    for i in range(start_timestep,(number_timesteps + 1)):\n",
    "        start = time.time()\n",
    "        print(\"\\nNumber of features \", i)\n",
    "        X, y = last_energy_points(df, i)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = split_train_test_timeseries(X,y, train_size=train_size)\n",
    "\n",
    "        model, preds, scores = build_model(estimator, X_train, y_train, X_test)\n",
    "        mse, rmse, mae, wape, r2 = performance_metrics(preds, y_test.values.reshape(-1))\n",
    "        cv_mse = np.round(scores['test_neg_mean_squared_error'].mean() * (-1),5)\n",
    "        cv_rmse = np.round(scores['test_neg_root_mean_squared_error'].mean() * (-1),5)\n",
    "        cv_mae = np.round(scores['test_neg_mean_absolute_error'].mean() * (-1),5)\n",
    "        cv_r2 = np.round(scores['test_r2'].mean(),5)\n",
    "        print(\"CV MSE: {} \".format(cv_mse))\n",
    "        print(\"CV RMSE: {} \".format(cv_rmse))\n",
    "        print(\"CV MAE: {} \".format(cv_mae))\n",
    "        print(\"CV R2: {} \".format(cv_r2))\n",
    "        metrics_list.append((cv_mse,cv_rmse,cv_mae,mape,cv_r2))s\n",
    "        print(\"\\nElapsed time: {} seconds\".format(time.time() - start))\n",
    "    print(\"\\nFull Elapsed time: {} seconds\".format(time.time() - full_start))\n",
    "    return model, preds, scores, metrics_list\n",
    "\n",
    "def split_train_test_timeseries(X, y, train_size: int):\n",
    "    n_train_samples = int(len(X) * train_size)\n",
    "    X_train = X[:n_train_samples]\n",
    "    X_test = X[n_train_samples:]\n",
    "    y_train = y[:n_train_samples]\n",
    "    y_test = y[n_train_samples:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def show_graphic_per_timestep(metrics_list, number_timesteps, start_timestep=1):\n",
    "    mse_list = []\n",
    "    rmse_list = []\n",
    "    mae_list = []\n",
    "    wape_list = []\n",
    "    r2_list = []\n",
    "\n",
    "    for i in range(0,len(metrics_list)):\n",
    "        mse_list.append(metrics_list[i][0][0])\n",
    "        rmse_list.append(metrics_list[i][0][1])\n",
    "        mae_list.append(metrics_list[i][0][2])\n",
    "        wape_list.append(metrics_list[i][0][3])\n",
    "        r2_list.append(metrics_list[i][0][4])\n",
    "        \n",
    "    plt.plot(range(0,number_of_houses), mse_list)\n",
    "    plt.title('MSE per house')\n",
    "    plt.xlabel('Number of houses')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(range(0,number_of_houses), rmse_list)\n",
    "    plt.title('RMSE per house')\n",
    "    plt.xlabel('Number of houses')\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(range(0,number_of_houses), mae_list)\n",
    "    plt.title('MAE per house')\n",
    "    plt.xlabel('Number of houses')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(range(0,number_of_houses), wape_list)\n",
    "    plt.title('WAPE per house')\n",
    "    plt.xlabel('Number of houses')\n",
    "    plt.ylabel('WAPE')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(range(0,number_of_houses), r2_list)\n",
    "    plt.title('R2 per house')\n",
    "    plt.xlabel('Number of houses')\n",
    "    plt.ylabel('R2')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0e80f3",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cfbb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = df.values\n",
    "scaler = MinMaxScaler()\n",
    "df_scaled = scaler.fit_transform(values)\n",
    "df_scaled = pd.DataFrame(df_scaled)\n",
    "df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d319234",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f226c552",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = last_energy_points(df[0], 2)\n",
    "print(X.shape, y.shape)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905a93b1",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630487f8",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7deb62aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_timestep = 10\n",
    "number_timesteps = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6d444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_gb, preds_gb, scores_gb, metrics_list_gb = [],[],[],[]\n",
    "start_t = time.time()\n",
    "for house in range(0,number_of_houses):\n",
    "    print(\"\\n House {}\".format(house))\n",
    "    mo_gb, p_gb, s_gb, ml_gb = build_predict_show(df[house], number_timesteps, GradientBoostingRegressor(random_state=42), start_timestep=start_timestep)\n",
    "    model_gb.append(mo_gb)\n",
    "    preds_gb.append(p_gb)\n",
    "    scores_gb.append(s_gb)\n",
    "    metrics_list_gb.append(ml_gb)\n",
    "print(\"\\nFull Elapsed time: {} seconds\".format(time.time() - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14953027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graphic_per_timestep(metrics_list_gb, number_timesteps, start_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643652f",
   "metadata": {},
   "source": [
    "#### Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198922bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_gb_norm, preds_gb_norm, scores_gb_norm, metrics_list_gb_norm = [],[],[],[]\n",
    "start_t = time.time()\n",
    "for house in range(0,number_of_houses):\n",
    "    print(\"\\n House {}\".format(house))\n",
    "    mo_gb, p_gb, s_gb, ml_gb = build_predict_show(df_scaled[house], number_timesteps, GradientBoostingRegressor(random_state=42), start_timestep=start_timestep)\n",
    "    model_gb_norm.append(mo_gb)\n",
    "    preds_gb_norm.append(p_gb)\n",
    "    scores_gb_norm.append(s_gb)\n",
    "    metrics_list_gb_norm.append(ml_gb)\n",
    "print(\"\\nFull Elapsed time: {} seconds\".format(time.time() - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578c798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graphic_per_timestep(metrics_list_gb_norm, number_timesteps, start_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e651902",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e2395a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rf, preds_rf, scores_rf, metrics_list_rf = [],[],[],[]\n",
    "for house in range(0,number_of_houses):\n",
    "    print(\"\\n House {}\".format(house))\n",
    "    mo_rf, p_rf, s_rf, ml_rf = build_predict_show(df[house], number_timesteps, RandomForestRegressor(random_state=42), start_timestep=start_timestep)\n",
    "    model_rf.append(mo_rf)\n",
    "    preds_rf.append(p_rf)\n",
    "    scores_rf.append(s_rf)\n",
    "    metrics_list_rf.append(ml_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54edc90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graphic_per_timestep(metrics_list_rf, number_timesteps, start_timestep=start_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859be1fe",
   "metadata": {},
   "source": [
    "#### Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0868c58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_rf_norm, preds_rf_norm, scores_rf_norm, metrics_list_rf_norm = [],[],[],[]\n",
    "start_t = time.time()\n",
    "for house in range(0,number_of_houses):\n",
    "    print(\"\\n House {}\".format(house))\n",
    "    mo_rf, p_rf, s_rf, ml_rf = build_predict_show(df_scaled[house], number_timesteps, RandomForestRegressor(random_state=42), start_timestep=start_timestep)\n",
    "    model_rf_norm.append(mo_rf)\n",
    "    preds_rf_norm.append(p_rf)\n",
    "    scores_rf_norm.append(s_rf)\n",
    "    metrics_list_rf_norm.append(ml_rf)\n",
    "print(\"\\nFull Elapsed time: {} seconds\".format(time.time() - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fee84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_graphic_per_timestep(metrics_list_rf_norm, number_timesteps, start_timestep=start_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae33951",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30af10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_xgb, preds_xgb, scores_xgb, metrics_list_xgb = [],[],[],[]\n",
    "start_t = time.time()\n",
    "for house in range(0,number_of_houses):\n",
    "    print(\"\\n House {}\".format(house))\n",
    "    mo_xgb, p_xgb, s_xgb, ml_xgb = build_predict_show(df[house], number_timesteps, xgb.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=100, seed=42), start_timestep=start_timestep)\n",
    "    model_xgb.append(mo_xgb)\n",
    "    preds_xgb.append(p_xgb)\n",
    "    scores_xgb.append(s_xgb)\n",
    "    metrics_list_xgb.append(ml_xgb)\n",
    "print(\"\\XGBoost Elapsed time: {} seconds\".format(time.time() - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36941c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graphic_per_timestep(metrics_list_xgb, number_timesteps, start_timestep=start_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad2bfc",
   "metadata": {},
   "source": [
    "#### Normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7c7026",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_xgb_norm, preds_xgb_norm, scores_xgb_norm, metrics_list_xgb_norm = [],[],[],[]\n",
    "start_t = time.time()\n",
    "for house in range(0,number_of_houses):\n",
    "    print(\"\\n House {}\".format(house))\n",
    "    mo_xgb, p_xgb, s_rf, ml_xgb = build_predict_show(df_scaled[house], number_timesteps, xgb.XGBRegressor(max_depth=5, learning_rate=0.1, n_estimators=100, seed=42), start_timestep=start_timestep)\n",
    "    model_xgb_norm.append(mo_xgb)\n",
    "    preds_xgb_norm.append(p_xgb)\n",
    "    scores_xgb_norm.append(s_xgb)\n",
    "    metrics_list_xgb_norm.append(ml_xgb)\n",
    "print(\"\\nFull Elapsed time: {} seconds\".format(time.time() - start_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba011f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_graphic_per_timestep(metrics_list_xgb_norm, number_timesteps, start_timestep=start_timestep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249af263",
   "metadata": {},
   "source": [
    "### Total average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98260572",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_ave()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e7615",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(min([sublist[3] for sublist in metrics_list_gb]))\n",
    "print(min([sublist[3] for sublist in metrics_list_gb_norm]))\n",
    "print(min([sublist[3] for sublist in metrics_list_rf]))\n",
    "print(min([sublist[3] for sublist in metrics_list_rf_norm]))\n",
    "print(min([sublist[3] for sublist in metrics_list_xgb]))\n",
    "print(min([sublist[3] for sublist in metrics_list_xgb_norm]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ed32d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_metric(metric: str):\n",
    "    if metric.lower() == \"mse\":\n",
    "        m = 0\n",
    "    elif metric.lower() == \"rmse\":\n",
    "        m = 1\n",
    "    elif metric.lower() == \"mae\":\n",
    "        m = 2\n",
    "    elif metric.lower() == \"wape\":\n",
    "        m = 3\n",
    "    elif metric.lower() == \"r2\":\n",
    "        m = 4\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bbe364",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_model(metric: str, metrics_list):\n",
    "    met = switch_metric(metric)\n",
    "    min_value = min(map(lambda x: x[met], metrics_list))\n",
    "    idx = [index for index, item in enumerate(map(lambda x: x[met], metrics_list)) if item == min_value]\n",
    "    return metrics_list[idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3d522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics_lists = [metrics_list_gb, metrics_list_gb_norm, metrics_list_rf, metrics_list_rf_norm, metrics_list_xgb, metrics_list_xgb_norm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371e6e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = []\n",
    "for model in all_metrics_lists:\n",
    "    best_model.append(find_best_model(\"wape\", model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3d21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names = (\"WAPE\", \"R2\")\n",
    "X_axis = np.arange(len(X_names))\n",
    "plt.bar(X_axis - 0.2, (best_model[0][3], best_model[0][4]), 0.2, label = 'Denormalized GB')\n",
    "plt.bar(X_axis, (best_model[2][3], best_model[2][4]), 0.2, label = 'Denormalized RF')\n",
    "plt.bar(X_axis + 0.2, (best_model[4][3], best_model[4][4]), 0.2, label = 'Denormalized XGB')\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(X_axis, X_names)\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Vales\")\n",
    "plt.title(\"Denormalized models\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99b6ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names = (\"WAPE\", \"R2\")\n",
    "X_axis = np.arange(len(X_names))\n",
    "plt.bar(X_axis - 0.4, (best_model[1][3], best_model[1][4]), 0.2, label = 'Normalized GB')\n",
    "plt.bar(X_axis + 0, (best_model[3][3], best_model[3][4]), 0.2, label = 'Normalized RF')\n",
    "plt.bar(X_axis + 0.4, (best_model[5][3], best_model[5][4]), 0.2, label = 'Normalized XGB')\n",
    "\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(X_axis, X_names)\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Normalized Models)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a8c016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names = (\"WAPE\", \"R2\")\n",
    "X_axis = np.arange(len(X_names))\n",
    "plt.bar(X_axis - 0.2, (best_model[0][3], best_model[0][4]), 0.4, label = 'Denormalized GB')\n",
    "plt.bar(X_axis + 0.2, (best_model[1][3], best_model[1][4]), 0.4, label = 'Normalized GB')\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(X_axis, X_names)\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Normalized vs Denormalized GB\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d50c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names = (\"WAPE\", \"R2\")\n",
    "X_axis = np.arange(len(X_names))\n",
    "plt.bar(X_axis - 0.2, (best_model[2][3], best_model[2][4]), 0.4, label = 'Denormalized RF')\n",
    "plt.bar(X_axis + 0.2, (best_model[3][3], best_model[3][4]), 0.4, label = 'Normalized RF')\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(X_axis, X_names)\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Normalized vs Denormalized RF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a44463",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_names = (\"WAPE\", \"R2\")\n",
    "X_axis = np.arange(len(X_names))\n",
    "plt.bar(X_axis - 0.2, (best_model[4][3], best_model[4][4]), 0.4, label = 'Denormalized XGB')\n",
    "plt.bar(X_axis + 0.2, (best_model[5][3], best_model[5][4]), 0.4, label = 'Normalized XGB')\n",
    "plt.ylim(0,1)\n",
    "plt.xticks(X_axis, X_names)\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Normalized vs Denormalized\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb90e31e",
   "metadata": {},
   "source": [
    "## Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd4cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = np.zeros((params['n_estimators'],), dtype=np.float64)\n",
    "for i, y_pred in enumerate(model.staged_predict(X_test)):\n",
    "    test_score[i] = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.title(\"Deviance\")\n",
    "plt.plot(\n",
    "    np.arange(params['n_estimators']) + 1,\n",
    "    model.train_score_,\n",
    "    \"b-\",\n",
    "    label=\"Training Set Deviance\",\n",
    ")\n",
    "plt.plot(\n",
    "    np.arange(params['n_estimators']) + 1, test_score, \"r-\", label=\"Test Set Deviance\"\n",
    ")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel(\"Boosting Iterations\")\n",
    "plt.ylabel(\"Deviance\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e0321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = model.feature_importances_\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "pos = np.arange(sorted_idx.shape[0]) + 0.5\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.barh(pos, feature_importance[sorted_idx], align=\"center\")\n",
    "plt.yticks(pos,X_test.columns)\n",
    "plt.title(\"Feature Importance (MDI)\")\n",
    "\n",
    "result = permutation_importance(\n",
    "    model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=2\n",
    ")\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(\n",
    "    result.importances[sorted_idx].T,\n",
    "    vert=False,\n",
    "    labels=X_test.columns,\n",
    ")\n",
    "plt.title(\"Permutation Importance (test set)\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29bbdc",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2d6efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = dict()\n",
    "grid['n_estimators'] = [50, 100, 500]\n",
    "grid['learning_rate'] = [0.001, 0.01, 0.1, 0.3]\n",
    "grid['subsample'] = [0.5, 0.7, 1.0]\n",
    "grid['max_depth'] = [3, 7, 9]\n",
    "\n",
    "model = GradientBoostingRegressor()\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "#grid_search = RandomizedSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv)\n",
    "grid_result = grid_search.fit(X, y.values.ravel())\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af49a92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
