{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58081526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=FutureWarning)\n",
    "warnings.filterwarnings('ignore',category=DeprecationWarning)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate, KFold, RepeatedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import time\n",
    "import cudf\n",
    "from cuml.ensemble import RandomForestRegressor as cuRF\n",
    "import math\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa402221",
   "metadata": {},
   "source": [
    "#### Output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "70c13e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFile = open(\"gpu_logs/ensemble_porto_672.txt\", 'w')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8907202",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f6963e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Location</th>\n",
       "      <th>Energy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.322959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.371797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.415961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.302538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2.363063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756795</th>\n",
       "      <td>2020-01-01 22:45:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.753222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756796</th>\n",
       "      <td>2020-01-01 23:00:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.716855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756797</th>\n",
       "      <td>2020-01-01 23:15:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.735802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756798</th>\n",
       "      <td>2020-01-01 23:30:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.485237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1756799</th>\n",
       "      <td>2020-01-01 23:45:00</td>\n",
       "      <td>50</td>\n",
       "      <td>0.394216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1756800 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Time  Location    Energy\n",
       "0       2019-01-01 00:00:00         1  2.322959\n",
       "1       2019-01-01 00:15:00         1  2.371797\n",
       "2       2019-01-01 00:30:00         1  2.415961\n",
       "3       2019-01-01 00:45:00         1  2.302538\n",
       "4       2019-01-01 01:00:00         1  2.363063\n",
       "...                     ...       ...       ...\n",
       "1756795 2020-01-01 22:45:00        50  0.753222\n",
       "1756796 2020-01-01 23:00:00        50  0.716855\n",
       "1756797 2020-01-01 23:15:00        50  0.735802\n",
       "1756798 2020-01-01 23:30:00        50  0.485237\n",
       "1756799 2020-01-01 23:45:00        50  0.394216\n",
       "\n",
       "[1756800 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../datasets/df_location.pkl\")\n",
    "## Leaving the first house (public building out) due to its different profile\n",
    "df = df.iloc[35136:, [0, 2, 1]].reset_index(drop=True)\n",
    "number_of_houses = df.Location.nunique()\n",
    "num_samples_per_house = df.Location.value_counts()[1]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f318159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trunc = lambda x: math.trunc(10000 * x) / 10000\n",
    "#df_trunc = pd.DataFrame(df['Energy']).applymap(trunc)\n",
    "#df = pd.concat([df.iloc[:, 0:-1], df_trunc], axis=1)\n",
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c9d325",
   "metadata": {},
   "source": [
    "### Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cd78e17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(preds: np.array, actuals: np.array, title: str):\n",
    "    \n",
    "    plt.scatter(actuals, preds, c='b', label='predicted')\n",
    "    plt.xlabel('actual')\n",
    "    plt.ylabel('predicted')\n",
    "    plt.title(title)\n",
    "    plt.xlim(0, plt.xlim()[1])\n",
    "    plt.ylim(0, plt.ylim()[1])\n",
    "    _ = plt.plot([0, 100], [0, 100], '--r', label='y=x')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def truncate_metric(metric):\n",
    "    m = math.trunc(10000 * metric) / 10000\n",
    "    return m \n",
    "    \n",
    "def performance_metrics(preds: np.array, actuals: np.array, filename):\n",
    "\n",
    "    # calculate performance metrics\n",
    "    \n",
    "    mse = truncate_metric(mean_squared_error(actuals, preds))\n",
    "    wape = truncate_metric(np.sum(np.abs(preds - actuals)) / np.sum(np.abs(actuals))) * 100\n",
    "    r2 = truncate_metric(r2_score(actuals, preds))\n",
    "    \n",
    "    # print performance metrics\n",
    "    print('MSE: %.4f' % mse, file=filename)\n",
    "    print('WAPE: %.2f' % wape, file=filename)\n",
    "    print('R2: %.4f' % r2, file=filename)\n",
    "    return mse, wape, r2\n",
    "\n",
    "#@jit(target_backend='cuda')\n",
    "def build_model(estimator, X_train: np.array, y_train: np.array, X_test: np.array):\n",
    "    \n",
    "    model = estimator\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    return model, preds\n",
    "\n",
    "def validate(estimator, X_train, y_train):\n",
    "    scores = cross_validate(estimator, X_train, y_train, scoring=['r2', 'neg_mean_squared_error'])\n",
    "    return scores\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8af19e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_averaged_metrics(metrics_list, filename):\n",
    "    \n",
    "    print(\"Total Averaged MSE: {}\".format(np.round(sum(i for i, j, k in metrics_list)/len(metrics_list),3)), file=filename)\n",
    "    print(\"Total Averaged WAPE: {}\".format(np.round(sum(j for i, j, k in metrics_list)/len(metrics_list),3)), file=filename)\n",
    "    print(\"Total Averaged R2: {}\".format(np.round(sum(k for i, j, k in metrics_list)/len(metrics_list),3)), file=filename)\n",
    "\n",
    "def past_timesteps(df, number_of_timesteps):\n",
    "    df = df.sort_values(by=['Location', 'Time'])\n",
    "    for i in tqdm(range(1, (number_of_timesteps + 1))):\n",
    "        df.loc[df['Time'].shift(i) == df['Time'] - pd.Timedelta(i * 15, 'm'), f\"energy_lag_{i}\"] = df['Energy'].shift(i)\n",
    "    df.dropna(inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "#def past_timesteps(df, number_of_timesteps):\n",
    "#    # Sort the dataframe by location and time\n",
    "#    df = df.sort_values(by=['Location', 'Time'])\n",
    "#\n",
    "#    # Compute rolling window over time axis to extract past energy values for each location\n",
    "#    energy_lags = [f\"energy_lag_{i}\" for i in range(1, number_of_timesteps+1)]\n",
    "#    past_energy = df.groupby('Location')['Energy'].rolling(window=number_of_timesteps, min_periods=1).apply(np.mean())\n",
    "#    # Add new columns to the dataframe for each past energy value\n",
    "#    for i, energy_lag in enumerate(energy_lags):\n",
    "#        df[energy_lag] = past_energy.apply(lambda x: x[-i-1] if isinstance(x, list) and len(x)>=i+1 else x)\n",
    "#\n",
    "#    # Drop rows with missing values\n",
    "#    df.dropna(inplace=True)\n",
    "#    df.reset_index(drop=True, inplace=True)\n",
    "#\n",
    "#    return df\n",
    "\n",
    "\n",
    "def last_energy_points_full(df, number_timesteps, num_samples_per_house):\n",
    "    X = pd.DataFrame()\n",
    "    other_feats = df.iloc[:,:2]\n",
    "    for i in range(1, (number_timesteps + 1) ):\n",
    "        X[f'Energy_{i*15}'] = df['Energy'].shift(i)\n",
    "    y = df.copy().iloc[:,2]\n",
    "    y.iloc[:number_timesteps] = np.nan\n",
    "    ## Remove samples in between each house\n",
    "    for h in range(1, number_of_houses):\n",
    "        for i in range(0, number_timesteps):\n",
    "            X.iloc[(num_samples_per_house+i)*h] = np.nan\n",
    "            y.iloc[(num_samples_per_house+i)*h] = np.nan\n",
    "    X = pd.concat([other_feats, X], axis=1)\n",
    "    X.dropna(inplace=True)\n",
    "    X.reset_index(drop=True, inplace=True)\n",
    "    y.dropna(inplace=True)\n",
    "    y.reset_index(drop=True, inplace=True)\n",
    "    y.columns = [\"Energy\"]\n",
    "    dataframe = pd.concat([X,y.rename('Energy')], axis=1)\n",
    "    assert number_of_houses == (df.shape[0] - dataframe.shape[0]) / number_timesteps, \"Something went wrong with preprocessing\"\n",
    "    return dataframe\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9d0352ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_training(X_train):\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    scaler.fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    return X_train, scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1b0d17",
   "metadata": {},
   "source": [
    "### Cross Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "71efa19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scores = validate(xgb.XGBRegressor(seed=0), X_train, y_train)\n",
    "#cv_mse = np.round(scores['test_neg_mean_squared_error'].mean() * (-1),4)\n",
    "#cv_r2 = np.round(scores['test_r2'].mean(),5)\n",
    "#print(\"CV MSE: {} \".format(cv_mse))\n",
    "#print(\"CV R2: {} \".format(cv_r2))\n",
    "#metrics_list.append((cv_mse,cv_rmse,cv_mae,mape,cv_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ba7c5",
   "metadata": {},
   "source": [
    "## Leave 10 houses for test (demonstration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "fd9b27b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_timesteps = 672"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ddb42d91",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "_mean_dispatcher() missing 1 required positional argument: 'a'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[141], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_new \u001b[39m=\u001b[39m past_timesteps(df, number_of_timesteps)\n\u001b[1;32m      2\u001b[0m df_new\n",
      "Cell \u001b[0;32mIn[137], line 21\u001b[0m, in \u001b[0;36mpast_timesteps\u001b[0;34m(df, number_of_timesteps)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39m# Compute rolling window over time axis to extract past energy values for each location\u001b[39;00m\n\u001b[1;32m     20\u001b[0m energy_lags \u001b[39m=\u001b[39m [\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39menergy_lag_\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, number_of_timesteps\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[0;32m---> 21\u001b[0m past_energy \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mLocation\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39mEnergy\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mrolling(window\u001b[39m=\u001b[39mnumber_of_timesteps, min_periods\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mapply(np\u001b[39m.\u001b[39;49mmean())\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(past_energy)\n\u001b[1;32m     23\u001b[0m \u001b[39m# Add new columns to the dataframe for each past energy value\u001b[39;00m\n",
      "File \u001b[0;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: _mean_dispatcher() missing 1 required positional argument: 'a'"
     ]
    }
   ],
   "source": [
    "df_new = past_timesteps(df, number_of_timesteps)\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6cf023",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa9a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_leave_house_out(df, estimator, number_timesteps, num_houses_test, locations, filename):\n",
    "    df_new = past_timesteps(df, number_timesteps)\n",
    "    df_new['DayOfWeek'] = df_new['Time'].dt.dayofweek\n",
    "    df_new['Weekend'] = df_new['Time'].dt.dayofweek.isin([5,6]).astype(int)\n",
    "    df_new['Hour'] = df_new['Time'].dt.hour\n",
    "    test = df_new[df_new['Location'].isin(locations)]\n",
    "    train = df_new[~df_new['Location'].isin(locations)]\n",
    "    print(\"Train set: \", train.shape)\n",
    "    print(\"Test set: \", test.shape)\n",
    "    X_train = train.drop(['Time', 'Energy', 'Location'], axis=1)\n",
    "    X_test = test.drop(['Time', 'Energy', 'Location'], axis=1)\n",
    "    y_train = train['Energy']\n",
    "    y_test = test['Energy']\n",
    "    X_train_norm, scaler = normalize_training(X_train)\n",
    "    X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "    model = estimator\n",
    "    init = time.time()\n",
    "    model.fit(X_train_norm, y_train)\n",
    "    y_pred = model.predict(X_test_norm)\n",
    "    end = time.time()\n",
    "    print('Elapsed time: {:.4f} s'.format(end - init), file=filename)\n",
    "    mse, wape, r2 = performance_metrics(y_pred, y_test.values.reshape(-1), filename)\n",
    "    return mse, wape, r2, model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b7a1a3",
   "metadata": {},
   "source": [
    "## Predict  10 folds with 10 random houses for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d93f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_houses_test = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b164a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = RepeatedKFold(n_splits=5, n_repeats=2, random_state=42) \n",
    "locations = []\n",
    "for _, test_index in kf.split(df['Location'].unique()):\n",
    "    locations.append(test_index)\n",
    "locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc7da60",
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = []\n",
    "for i in range(10):\n",
    "    l = np.random.choice(df['Location'].unique(), size=num_houses_test, replace=False)\n",
    "    locations.append(l)\n",
    "locations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e48b6b",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cfe1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list_lr = []\n",
    "print(\"\\n----------------------------\", file=sourceFile)\n",
    "print(\"\\nLinear Regression\\n\", file=sourceFile)\n",
    "print(\"----------------------------\\n\", file=sourceFile)\n",
    "for i in range(10):\n",
    "    print(\"\\nIteration\", i, file=sourceFile)\n",
    "    mse, wape, r2, model_lr = test_leave_house_out(df, LinearRegression(), number_of_timesteps, num_houses_test, locations[i], sourceFile)\n",
    "    metrics_list_lr.append((mse, wape, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4142f8",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29000235",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list_xgb = []\n",
    "print(\"\\n----------------------------\", file=sourceFile)\n",
    "print(\"\\nXGBoost\\n\", file=sourceFile)\n",
    "print(\"----------------------------\\n\", file=sourceFile)\n",
    "for i in range(10):\n",
    "    print(\"\\nIteration\", i, file=sourceFile)\n",
    "    mse, wape, r2, model_xgb = test_leave_house_out(df, xgb.XGBRegressor(tree_method='gpu_hist', seed=0), number_of_timesteps, num_houses_test, locations[i], sourceFile)\n",
    "    metrics_list_xgb.append((mse, wape, r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81a8ce",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a082e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list_rf = []\n",
    "print(\"\\n----------------------------\", file=sourceFile)\n",
    "print(\"\\nRandom Forest\\n\", file=sourceFile)\n",
    "print(\"----------------------------\\n\", file=sourceFile)\n",
    "for i in range(10):\n",
    "    print(\"\\nIteration\", i, file=sourceFile)\n",
    "    mse, wape, r2, model_rf = test_leave_house_out(df, cuRF(), number_of_timesteps, num_houses_test, locations[i], sourceFile)\n",
    "    metrics_list_rf.append((mse, wape, r2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d80b4bb",
   "metadata": {},
   "source": [
    "## Averaged Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\\n\", file=sourceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d11803",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLinear Regression\", file=sourceFile)\n",
    "total_averaged_metrics(metrics_list_lr, sourceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nXGBoost\", file=sourceFile)\n",
    "total_averaged_metrics(metrics_list_xgb, sourceFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRandom Forest\", file=sourceFile)\n",
    "total_averaged_metrics(metrics_list_rf, sourceFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5c8ff5",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7d8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear Regression\\n')\n",
    "for i,v in enumerate(model_lr.coef_):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "print('XGBoost\\n')\n",
    "for i,v in enumerate(model_xgb.feature_importances_):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f698b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(model_xgb.feature_importances_)),model_xgb.feature_importances_)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71aef5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(len(model_lr.coef_)),model_lr.coef_)\n",
    "plt.title('Feature Importance')\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa50a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dcc203",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
